<?xml version="1.0" encoding="utf-8" ?>
<ContentPage xmlns="http://schemas.microsoft.com/dotnet/2021/maui"
             xmlns:x="http://schemas.microsoft.com/winfx/2009/xaml"
             x:Class="TheoryHub.Views.ClassicMLTopic4"
             Title="Классификаторы">
    <ScrollView>
        <VerticalStackLayout Padding="5">

            <!-- Раздел: Теория -->
            <Label Text="Теория" 
                   FontSize="22" FontAttributes="Bold" 
                   TextColor="{StaticResource Primary}" Padding="15,0,0,0"/>
            <VerticalStackLayout Spacing="10" Padding="20">
                <Label Text="    Классификаторы представляют собой фундаментальную категорию алгоритмов машинного обучения с учителем, основной задачей которых является отнесение объектов к одному из заранее определённых классов (категорий) на основе их признаков. В отличие от регрессии, предсказывающей непрерывные величины, классификация имеет дело с дискретными метками. Работа классификатора начинается с обучения на размеченных данных, где каждому объекту сопоставлена верная категория. В процессе обучения алгоритм выявляет закономерности и взаимосвязи между признаками объектов и их целевыми метками, формируя решающую функцию или границу принятия решений. Эта граница в пространстве признаков разделяет области, соответствующие разным классам, что позволяет в дальнейшем классифицировать новые, ранее не встречавшиеся объекты."
                       FontSize="16" LineBreakMode="WordWrap"/>

                <Label Text="    Существует множество разнообразных алгоритмов классификации, каждый из которых основан на своей математической и философской концепции. Например, дерево решений строит иерархическую структуру правил «если-то», последовательно разделяя данные по значениям признаков. Метод k-ближайших соседей (k-NN) относится к ленивым алгоритмам и классифицирует объект на основе меток наиболее похожих на него обучающих примеров. Наивный байесовский классификатор опирается на теорему Байеса и предположение о независимости признаков. Более сложные методы, такие как метод опорных векторов (SVM), стремятся найти разделяющую гиперплоскость с максимальным зазором между классами, демонстрируя высокую эффективность в пространствах высокой размерности. Ансамбли моделей, например случайный лес или градиентный бустинг, объединяют предсказания множества слабых классификаторов (часто деревьев), достигая высокой точности и устойчивости к переобучению."
                        FontSize="16" LineBreakMode="WordWrap"/>

                <Label Text="    Оценка качества классификатора является отдельной и важнейшей задачей. Для её проведения выделяется тестовая выборка, не участвовавшая в обучении. Основными метриками являются точность, полнота, F-мера и AUC-ROC. Выбор метрики зависит от специфики задачи: в медицинской диагностике критически важна полнота выявления заболевания, а в задачах фильтрации спама — точность, чтобы минимизировать ложные срабатывания. Понимание природы данных и контекста задачи является ключевым фактором при выборе подходящего алгоритма классификации, его настройке и интерпретации результатов."
                       FontSize="16" LineBreakMode="WordWrap"/>

            </VerticalStackLayout>
            <BoxView HeightRequest="1" Color="LightGray" Margin="0,10"/>

            <!-- Раздел: Термины -->
            <Label Text="Термины" 
                   FontSize="22" FontAttributes="Bold" 
                   TextColor="{StaticResource Primary}" Padding="15,0,0,0"/>

            <StackLayout Spacing="10" Padding="10">
                <Frame x:Name="term1_topic4" BackgroundColor="#F0F0F0" Padding="10">
                    <Frame.GestureRecognizers>
                        <TapGestureRecognizer Tapped="OnTermFrameTapped"/>
                    </Frame.GestureRecognizers>
                    <Label Text="Решающая граница (Decision Boundary)" FontSize="16" />
                </Frame>
                <Label x:Name="definition1_topic4"
                    Text="Это поверхность в пространстве признаков, которая разделяет объекты, отнесённые классификатором к разным классам. Для линейного классификатора (например, логистической регрессии) эта граница является гиперплоскостью. Для нелинейных моделей (например, полиномиального SVM или дерева решений) граница может иметь сложную, кусочно-линейную или нелинейную форму. Конфигурация решающей границы является наглядным представлением внутренней логики, выученной алгоритмом в процессе обучения."
                    IsVisible="False"
                    Padding="10,20,10,10" />
            </StackLayout>

            <StackLayout Spacing="10" Padding="10">
                <Frame x:Name="term2_topic4" BackgroundColor="#F0F0F0" Padding="10">
                    <Frame.GestureRecognizers>
                        <TapGestureRecognizer Tapped="OnTermFrameTapped"/>
                    </Frame.GestureRecognizers>
                    <Label Text="Ансамбль (Ensemble)" FontSize="16" />
                </Frame>
                <Label x:Name="definition2_topic4"
                    Text="Это мета-алгоритм, который объединяет прогнозы нескольких базовых классификаторов (часто называемых «слабыми учениками») с целью получения более точного и устойчивого итогового прогноза. Основная идея заключается в том, что коллективное решение множества моделей, допускающих разные ошибки, оказывается надёжнее решения одной, даже сложной модели. К основным подходам построения ансамблей относятся бэггинг (параллельное обучение моделей на разных бутстрап-выборках, как в случайном лесе) и бустинг (последовательное обучение, где каждая следующая модель фокусируется на ошибках предыдущих, как в AdaBoost или XGBoost)."
                    IsVisible="False"
                    Padding="10,20,10,10" />
            </StackLayout>

            <BoxView HeightRequest="1" Color="LightGray" Margin="0,10"/>

            <!-- Раздел: Вопросы -->
            <Label Text="Вопросы для самопроверки" 
                   FontSize="22" FontAttributes="Bold" 
                   TextColor="{StaticResource Primary}" Padding="15,0,0,0"/>

            <StackLayout Spacing="10" Padding="10">
                <Frame x:Name="question1_topic4" BackgroundColor="#F0F0F0" Padding="10">
                    <Frame.GestureRecognizers>
                        <TapGestureRecognizer Tapped="OnQuestionFrameTapped"/>
                    </Frame.GestureRecognizers>
                    <Label Text="В чём заключается ключевое различие между генеративными и дискриминативными моделями классификации?" FontSize="16"/>
                </Frame>
                <Label x:Name="answer1_topic4" 
                   Text="Ключевое различие лежит в том, как модель формирует своё решение. Дискриминативная модель (например, логистическая регрессия или SVM) напрямую обучается различать классы, находя границу принятия решений в пространстве признаков. Она моделирует условную вероятность P(класс | признаки) — вероятность класса при заданных признаках. Генеративная модель (например, наивный Байес) сначала изучает вероятностные распределения каждого класса в отдельности, то есть моделирует P(признаки | класс), а затем, используя теорему Байеса, выводит искомую P(класс | признаки). Проще говоря, дискриминативная модель учится разделять классы, а генеративная — описывать каждый класс изнутри."
                   IsVisible="False"
                   Padding="10,20,10,10" />
            </StackLayout>

            <StackLayout Spacing="10" Padding="10">
                <Frame x:Name="question2_topic4" BackgroundColor="#F0F0F0" Padding="10">
                    <Frame.GestureRecognizers>
                        <TapGestureRecognizer Tapped="OnQuestionFrameTapped"/>
                    </Frame.GestureRecognizers>
                    <Label Text="Почему точность (accuracy) может быть плохой метрикой для оценки классификатора на несбалансированных данных?" FontSize="16"/>
                </Frame>
                <Label x:Name="answer2_topic4" 
                   Text="Точность измеряет долю верно предсказанных объектов от общего их числа. В условиях сильного дисбаланса классов (например, 99% объектов класса A и 1% класса B) наивный классификатор, который всегда предсказывает мажоритарный класс A, достигнет точности в 99%, что формально является отличным результатом. Однако при этом он полностью провалит задачу обнаружения редкого, но часто критически важного класса B. Его полнота и точность для класса B будут нулевыми. Поэтому для несбалансированных задач используют другие метрики: полноту, точность, F-меру для миноритарного класса или макро-усреднённые версии этих метрик, которые учитывают качество предсказания для каждого класса в отдельности."
                   IsVisible="False"
                   Padding="10,20,10,10" />
            </StackLayout>
        </VerticalStackLayout>
    </ScrollView>
</ContentPage>