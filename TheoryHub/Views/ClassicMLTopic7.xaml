<?xml version="1.0" encoding="utf-8" ?>
<ContentPage xmlns="http://schemas.microsoft.com/dotnet/2021/maui"
             xmlns:x="http://schemas.microsoft.com/winfx/2009/xaml"
             x:Class="TheoryHub.Views.ClassicMLTopic7"
             Title="Линейная классификация">
    <ScrollView>
        <VerticalStackLayout Padding="5">

            <!-- Раздел: Теория -->
            <Label Text="Теория" 
                   FontSize="22" FontAttributes="Bold" 
                   TextColor="{StaticResource Primary}" Padding="15,0,0,0"/>
            <VerticalStackLayout Spacing="10" Padding="20">
                <Label Text="    Линейная классификация является одним из центральных подходов в машинном обучении с учителем, целью которого является разделение объектов разных классов с помощью линейной решающей границы. В основе этого семейства моделей лежит идея о том, что в пространстве признаков существует гиперплоскость, которая может эффективно отделять объекты, принадлежащие различным категориям. Математически такая гиперплоскость задаётся линейной комбинацией признаков объекта: если взвешенная сумма признаков превышает некоторый порог, объект относится к одному классу, в противном случае — к другому. Несмотря на кажущуюся простоту, линейные классификаторы демонстрируют высокую эффективность на множестве практических задач, особенно там, где данные являются линейно разделимыми или могут быть преобразованы в таковые с помощью техник ядерных методов."
                       FontSize="16" LineBreakMode="WordWrap"/>

                <Label Text="    Обучение линейного классификатора сводится к поиску оптимальных значений вектора весов и смещения, которые определяют положение и ориентацию разделяющей гиперплоскости. Для этого необходимо определить целевую функцию, часто называемую функцией потерь, которая количественно оценивает ошибки классификации на обучающей выборке. Процесс оптимизации направлен на минимизацию этой функции. Одним из наиболее распространённых алгоритмов является логистическая регрессия, которая, вопреки своему названию, является именно линейным классификатором. Она моделирует вероятность принадлежности объекта к положительному классу с помощью сигмоидной функции, преобразующей линейную комбинацию признаков в число от 0 до 1. Другим классическим примером служит метод опорных векторов, который стремится найти не просто любую разделяющую гиперплоскость, а ту, которая максимизирует зазор между ближайшими к ней объектами разных классов, что повышает устойчивость модели к переобучению."
                        FontSize="16" LineBreakMode="WordWrap"/>

                <Label Text="    Сила линейных классификаторов заключается не только в их вычислительной эффективности и интерпретируемости, но и в возможности расширения для решения нелинейных задач. С помощью так называемого kernel trick можно неявно отображать исходные признаки в пространство более высокой размерности, где данные становятся линейно разделимыми, сохраняя при этом вычислительную сложность, сопоставимую с работой в исходном пространстве. Кроме того, линейные модели служат фундаментальными строительными блоками для более сложных архитектур, таких как нейронные сети. Понимание принципов линейной классификации, включая её геометрическую интерпретацию, методы регуляризации для борьбы с переобучением и стратегии обучения, является обязательной основой для любого специалиста в области машинного обучения."
                       FontSize="16" LineBreakMode="WordWrap"/>

            </VerticalStackLayout>
            <BoxView HeightRequest="1" Color="LightGray" Margin="0,10"/>

            <!-- Раздел: Термины -->
            <Label Text="Термины" 
                   FontSize="22" FontAttributes="Bold" 
                   TextColor="{StaticResource Primary}" Padding="15,0,0,0"/>

            <StackLayout Spacing="10" Padding="10">
                <Frame x:Name="term1_topic7" BackgroundColor="#F0F0F0" Padding="10">
                    <Frame.GestureRecognizers>
                        <TapGestureRecognizer Tapped="OnTermFrameTapped"/>
                    </Frame.GestureRecognizers>
                    <Label Text="Решающая граница" FontSize="16" />
                </Frame>
                <Label x:Name="definition1_topic7"
                    Text="Это гиперповерхность в пространстве признаков, которая разделяет объекты, отнесённые моделью к разным классам. В контексте линейной классификации эта граница является линейной, то есть представляет собой гиперплоскость, задаваемую уравнением wᵀx + b = 0, где w — вектор весов, b — смещение (свободный член), а x — вектор признаков объекта. Все точки по одну сторону этой гиперплоскости классифицируются как один класс, по другую — как другой. Положение и ориентация границы определяются параметрами модели, найденными в процессе обучения."
                    IsVisible="False"
                    Padding="10,20,10,10" />
            </StackLayout>

            <StackLayout Spacing="10" Padding="10">
                <Frame x:Name="term2_topic7" BackgroundColor="#F0F0F0" Padding="10">
                    <Frame.GestureRecognizers>
                        <TapGestureRecognizer Tapped="OnTermFrameTapped"/>
                    </Frame.GestureRecognizers>
                    <Label Text="Функция потерь (Loss Function)" FontSize="16" />
                </Frame>
                <Label x:Name="definition2_topic7"
                    Text="Это математическая функция, которая количественно измеряет ошибку, совершаемую моделью классификации на каждом объекте обучающей выборки, сравнивая её предсказание с истинной меткой. Для линейной классификации типичными примерами являются логистическая функция потерь (перекрёстная энтропия), используемая в логистической регрессии, и hinge loss, используемая в методе опорных векторов. Цель процесса обучения — найти такие параметры модели, которые минимизируют среднее значение функции потерь на всём обучающем наборе данных."
                    IsVisible="False"
                    Padding="10,20,10,10" />
            </StackLayout>

            <BoxView HeightRequest="1" Color="LightGray" Margin="0,10"/>

            <!-- Раздел: Вопросы -->
            <Label Text="Вопросы для самопроверки" 
                   FontSize="22" FontAttributes="Bold" 
                   TextColor="{StaticResource Primary}" Padding="15,0,0,0"/>

            <StackLayout Spacing="10" Padding="10">
                <Frame x:Name="question1_topic7" BackgroundColor="#F0F0F0" Padding="10">
                    <Frame.GestureRecognizers>
                        <TapGestureRecognizer Tapped="OnQuestionFrameTapped"/>
                    </Frame.GestureRecognizers>
                    <Label Text="Чем принципиально отличается подход логистической регрессии от метода опорных векторов при построении линейного классификатора?" FontSize="16"/>
                </Frame>
                <Label x:Name="answer1_topic7" 
                   Text="Ключевое различие лежит в целевой функции, которую оптимизируют эти алгоритмы, и в получаемой решающей границе. Логистическая регрессия моделирует вероятности принадлежности к классам, минимизируя логистическую функцию потерь (перекрёстную энтропию). Она стремится найти такую гиперплоскость, которая максимизирует правдоподобие обучающих данных, но не обязательно обеспечивает максимальный зазор до объектов разных классов. Метод опорных векторов, напротив, минимизирует hinge loss и явно фокусируется на максимизации зазора между ближайшими к границе объектами классов. В результате SVM часто находит более «устойчивую» границу, определяемую лишь небольшим подмножеством обучающих точек — опорными векторами, и может быть менее чувствительным к выбросам в глубине классов."
                   IsVisible="False"
                   Padding="10,20,10,10" />
            </StackLayout>

            <StackLayout Spacing="10" Padding="10">
                <Frame x:Name="question2_topic7" BackgroundColor="#F0F0F0" Padding="10">
                    <Frame.GestureRecognizers>
                        <TapGestureRecognizer Tapped="OnQuestionFrameTapped"/>
                    </Frame.GestureRecognizers>
                    <Label Text="Почему для обучения линейных классификаторов часто используется регуляризация, и какие её основные типы применяются?" FontSize="16"/>
                </Frame>
                <Label x:Name="answer2_topic7" 
                   Text="Регуляризация применяется для предотвращения переобучения, которое возникает, когда модель становится слишком сложной и начинает «запоминать» шум в обучающих данных, теряя способность к обобщению. В контексте линейных классификаторов переобучение часто проявляется в чрезмерно больших по модулю значениях весовых коэффициентов. Регуляризация добавляет к основной функции потерь штрафное слагаемое, ограничивающее рост весов. Основные типы: L1-регуляризация (лассо), которая добавляет штраф, пропорциональный сумме абсолютных значений весов, что может обнулить часть из них и выполнить отбор признаков; и L2-регуляризация (гребневая), добавляющая штраф, пропорциональный сумме квадратов весов, что равномерно уменьшает все коэффициенты, не обнуляя их, и способствует устойчивости решения. Выбор типа регуляризации зависит от задачи: L1 полезен для интерпретируемости и отбора признаков, а L2 — для общей устойчивости модели."
                   IsVisible="False"
                   Padding="10,20,10,10" />
            </StackLayout>
        </VerticalStackLayout>
    </ScrollView>
</ContentPage>