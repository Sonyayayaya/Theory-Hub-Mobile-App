<?xml version="1.0" encoding="utf-8" ?>
<ContentPage xmlns="http://schemas.microsoft.com/dotnet/2021/maui"
             xmlns:x="http://schemas.microsoft.com/winfx/2009/xaml"
             x:Class="TheoryHub.Views.ClassicMLTopic6"
             Title="Линейная регрессия">
    <ScrollView>
        <VerticalStackLayout Padding="5">

            <!-- Раздел: Теория -->
            <Label Text="Теория" 
                   FontSize="22" FontAttributes="Bold" 
                   TextColor="{StaticResource Primary}" Padding="15,0,0,0"/>
            <VerticalStackLayout Spacing="10" Padding="20">
                <Label Text="    Линейная регрессия представляет собой один из фундаментальных и наиболее интерпретируемых алгоритмов машинного обучения с учителем, предназначенный для решения задач регрессии. Её цель — смоделировать линейную взаимосвязь между одной или несколькими независимыми переменными и одной непрерывной зависимой переменной. В основе модели лежит предположение о том, что целевая переменная может быть выражена как взвешенная сумма признаков плюс свободный член. Алгоритм находит такие коэффициенты при признаках, которые минимизируют разницу между предсказанными и фактическими значениями целевой переменной на обучающих данных. Простота и прозрачность линейной регрессии делают её не только рабочим инструментом для прогнозирования, но и отличной отправной точкой для понимания более сложных методов, а также мощным средством для анализа влияния факторов в экономике, биологии и социальных науках."
                       FontSize="16" LineBreakMode="WordWrap"/>

                <Label Text="    Процесс обучения линейной регрессии заключается в поиске оптимальных значений параметров модели. Наиболее распространённый метод — метод наименьших квадратов, который находит коэффициенты, минимизирующие сумму квадратов ошибок прогноза. Эта задача имеет аналитическое решение в виде формулы, что позволяет быстро вычислить параметры. Однако в случаях, когда число признаков очень велико или данные не помещаются в память, используют итеративные методы оптимизации, такие как градиентный спуск. Важным аспектом является проверка базовых предположений модели: линейности взаимосвязи, отсутствия сильной мультиколлинеарности признаков, гомоскедастичности и нормальности распределения ошибок. Нарушение этих допущений может привести к смещённым или неэффективным оценкам, поэтому перед использованием модели часто проводят диагностику остатков."
                        FontSize="16" LineBreakMode="WordWrap"/>

                <Label Text="    Несмотря на свою простоту, линейная регрессия служит основой для многих расширенных методов. Для борьбы с переобучением и улучшения обобщающей способности применяют регуляризацию: L1-регуляризация приводит к отбору признаков, обнуляя веса неважных переменных, а L2-регуляризация уменьшает величину весов, делая модель более устойчивой. Эти модификации известны как лассо и гребневая регрессия соответственно. Таким образом, линейная регрессия, будучи классическим инструментом, остаётся актуальной и гибкой основой, которая при грамотном применении и расширении позволяет решать широкий спектр практических задач прогнозирования."
                       FontSize="16" LineBreakMode="WordWrap"/>

            </VerticalStackLayout>
            <BoxView HeightRequest="1" Color="LightGray" Margin="0,10"/>

            <!-- Раздел: Термины -->
            <Label Text="Термины" 
                   FontSize="22" FontAttributes="Bold" 
                   TextColor="{StaticResource Primary}" Padding="15,0,0,0"/>

            <StackLayout Spacing="10" Padding="10">
                <Frame x:Name="term1_topic6" BackgroundColor="#F0F0F0" Padding="10">
                    <Frame.GestureRecognizers>
                        <TapGestureRecognizer Tapped="OnTermFrameTapped"/>
                    </Frame.GestureRecognizers>
                    <Label Text="Метод наименьших квадратов (МНК)" FontSize="16" />
                </Frame>
                <Label x:Name="definition1_topic6"
                    Text="Это стандартный подход к оценке параметров линейной регрессии, который определяет коэффициенты модели таким образом, чтобы минимизировать сумму квадратов разностей между наблюдаемыми значениями зависимой переменной и значениями, предсказанными моделью. Геометрически это можно представить как нахождение такой гиперплоскости, сумма квадратов расстояний от которой до всех точек данных является минимальной. МНК обеспечивает наилучшие линейные несмещённые оценки при соблюдении определённых статистических предположений."
                    IsVisible="False"
                    Padding="10,20,10,10" />
            </StackLayout>

            <StackLayout Spacing="10" Padding="10">
                <Frame x:Name="term2_topic6" BackgroundColor="#F0F0F0" Padding="10">
                    <Frame.GestureRecognizers>
                        <TapGestureRecognizer Tapped="OnTermFrameTapped"/>
                    </Frame.GestureRecognizers>
                    <Label Text="Регуляризация" FontSize="16" />
                </Frame>
                <Label x:Name="definition2_topic6"
                    Text="Это техника, используемая для предотвращения переобучения модели путём добавления к её функции потерь штрафного слагаемого за сложность коэффициентов. В контексте линейной регрессии наиболее распространены L1-регуляризация (лассо), которая добавляет штраф, пропорциональный сумме абсолютных значений коэффициентов, что может обнулять некоторые из них, и L2-регуляризация (гребневая), добавляющая штраф, пропорциональный сумме квадратов коэффициентов, что заставляет их равномерно уменьшаться. Регуляризация улучшает обобщающую способность модели, особенно при работе с данными высокой размерности или при наличии мультиколлинеарности."
                    IsVisible="False"
                    Padding="10,20,10,10" />
            </StackLayout>

            <BoxView HeightRequest="1" Color="LightGray" Margin="0,10"/>

            <!-- Раздел: Вопросы -->
            <Label Text="Вопросы для самопроверки" 
                   FontSize="22" FontAttributes="Bold" 
                   TextColor="{StaticResource Primary}" Padding="15,0,0,0"/>

            <StackLayout Spacing="10" Padding="10">
                <Frame x:Name="question1_topic6" BackgroundColor="#F0F0F0" Padding="10">
                    <Frame.GestureRecognizers>
                        <TapGestureRecognizer Tapped="OnQuestionFrameTapped"/>
                    </Frame.GestureRecognizers>
                    <Label Text="Что означает коэффициент при признаке в построенной модели линейной регрессии и как его интерпретировать?" FontSize="16"/>
                </Frame>
                <Label x:Name="answer1_topic6" 
                   Text="Коэффициент при признаке количественно показывает ожидаемое изменение значения целевой (зависимой) переменной при увеличении данного признака на одну единицу, при условии, что все остальные признаки остаются неизменными. Например, если в модели предсказания стоимости квартиры коэффициент при признаке «площадь» равен 0.1 (и цена измеряется в миллионах рублей), это означает, что увеличение площади на 1 квадратный метр, в среднем, приводит к увеличению прогнозируемой цены на 100 тысяч рублей при прочих равных условиях. Эта интерпретация справедлива только при соблюдении предположений модели, в частности, линейности взаимосвязи."
                   IsVisible="False"
                   Padding="10,20,10,10" />
            </StackLayout>

            <StackLayout Spacing="10" Padding="10">
                <Frame x:Name="question2_topic6" BackgroundColor="#F0F0F0" Padding="10">
                    <Frame.GestureRecognizers>
                        <TapGestureRecognizer Tapped="OnQuestionFrameTapped"/>
                    </Frame.GestureRecognizers>
                    <Label Text="Почему наличие сильной мультиколлинеарности среди признаков является проблемой для линейной регрессии?" FontSize="16"/>
                </Frame>
                <Label x:Name="answer2_topic6" 
                   Text="Мультиколлинеарность, то есть сильная коррелированность независимых переменных между собой, нарушает одно из ключевых предположений метода наименьших квадратов. Она приводит к нестабильности оценок коэффициентов: их значения и даже знаки могут резко меняться при незначительном изменении обучающих данных. Это затрудняет содержательную интерпретацию вклада каждого признака, поскольку их эффекты переплетены. С технической точки зрения, мультиколлинеарность делает матрицу признаков плохо обусловленной, что может вызывать численную неустойчивость при вычислении параметров модели. Для решения этой проблемы применяют отбор признаков, регуляризацию или используют методы снижения размерности, такие как главные компоненты."
                   IsVisible="False"
                   Padding="10,20,10,10" />
            </StackLayout>
        </VerticalStackLayout>
    </ScrollView>
</ContentPage>