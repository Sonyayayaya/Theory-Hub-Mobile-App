<?xml version="1.0" encoding="utf-8" ?>
<ContentPage xmlns="http://schemas.microsoft.com/dotnet/2021/maui"
             xmlns:x="http://schemas.microsoft.com/winfx/2009/xaml"
             x:Class="TheoryHub.Views.ClassicMLTopic5"
             Title="Метрики">
    <ScrollView>
        <VerticalStackLayout Padding="5">

            <!-- Раздел: Теория -->
            <Label Text="Теория" 
                   FontSize="22" FontAttributes="Bold" 
                   TextColor="{StaticResource Primary}" Padding="15,0,0,0"/>
            <VerticalStackLayout Spacing="10" Padding="20">
                <Label Text="    Метрики качества являются неотъемлемой частью процесса машинного обучения и служат объективным инструментом для оценки и сравнения производительности моделей. Они предоставляют количественную меру того, насколько хорошо алгоритм решает поставленную задачу, будь то классификация, регрессия или кластеризация. Выбор правильной метрики напрямую зависит от специфики задачи, природы данных и бизнес-требований, поскольку разные метрики отражают различные аспекты работы модели. Без адекватных метрик невозможно ни корректно обучить модель, подобрав оптимальные гиперпараметры, ни сравнить между собой разные подходы, ни оценить реальную ценность решения для конечного пользователя."
                       FontSize="16" LineBreakMode="WordWrap"/>

                <Label Text="    В задачах классификации базовым инструментом является матрица ошибок, которая наглядно показывает распределение верных и ошибочных предсказаний по классам. На её основе строятся такие ключевые метрики, как точность, полнота, F-мера и точность в узком смысле. Точность измеряет общую долю верно классифицированных объектов, но может вводить в заблуждение на несбалансированных данных. Полнота характеризует способность модели обнаруживать все объекты определённого класса, что критически важно в задачах медицинской диагностики. F-мера, являясь гармоническим средним точности и полноты, предлагает сбалансированную оценку, особенно для миноритарных классов. Для оценки вероятностных классификаторов широко используется ROC-кривая и площадь под ней — AUC-ROC, которая показывает способность модели ранжировать объекты, отделяя один класс от другого, независимо от выбранного порога классификации."
                        FontSize="16" LineBreakMode="WordWrap"/>

                <Label Text="    В регрессионных задачах, где целью является предсказание непрерывной величины, метрики оценивают ошибку прогноза. Наиболее распространены среднеквадратическая ошибка, которая сильно штрафует большие отклонения, и средняя абсолютная ошибка, более устойчивая к выбросам. Коэффициент детерминации позволяет оценить, какую долю дисперсии целевой переменной объясняет модель. Для задач кластеризации применяются внутренние метрики, такие как силуэтный коэффициент, оценивающий компактность и разделимость кластеров, и внешние метрики, требующие истинных меток, например, индекс Adjusted Rand Index. Понимание интерпретации, преимуществ и ограничений каждой метрики позволяет специалисту по данным не просто выбрать лучшую модель по формальному показателю, но и убедиться, что она действительно решает поставленную практическую проблему."
                       FontSize="16" LineBreakMode="WordWrap"/>

            </VerticalStackLayout>
            <BoxView HeightRequest="1" Color="LightGray" Margin="0,10"/>

            <!-- Раздел: Термины -->
            <Label Text="Термины" 
                   FontSize="22" FontAttributes="Bold" 
                   TextColor="{StaticResource Primary}" Padding="15,0,0,0"/>

            <StackLayout Spacing="10" Padding="10">
                <Frame x:Name="term1_topic5" BackgroundColor="#F0F0F0" Padding="10">
                    <Frame.GestureRecognizers>
                        <TapGestureRecognizer Tapped="OnTermFrameTapped"/>
                    </Frame.GestureRecognizers>
                    <Label Text="Матрица ошибок" FontSize="16" />
                </Frame>
                <Label x:Name="definition1_topic5"
                    Text="Это таблица, используемая для оценки производительности классификатора, которая сравнивает фактические целевые значения с предсказанными. Её строки обычно соответствуют истинным классам, а столбцы — предсказанным. Ключевыми элементами матрицы для бинарной классификации являются истинно положительные, ложноотрицательные, ложноположительные и истинно отрицательные случаи. Эта матрица является фундаментом для расчёта большинства других метрик классификации, так как предоставляет полную картину типов совершаемых моделью ошибок"
                    IsVisible="False"
                    Padding="10,20,10,10" />
            </StackLayout>

            <StackLayout Spacing="10" Padding="10">
                <Frame x:Name="term2_topic5" BackgroundColor="#F0F0F0" Padding="10">
                    <Frame.GestureRecognizers>
                        <TapGestureRecognizer Tapped="OnTermFrameTapped"/>
                    </Frame.GestureRecognizers>
                    <Label Text="Среднеквадратическая ошибка" FontSize="16" />
                </Frame>
                <Label x:Name="definition2_topic5"
                    Text="Это одна из основных метрик для оценки моделей регрессии. Она вычисляется как среднее арифметическое квадратов разностей между предсказанными моделью значениями и истинными значениями целевой переменной. MSE сильно чувствительна к выбросам из-за операции возведения в квадрат, что делает её полезной в ситуациях, когда крупные ошибки недопустимы. Часто для интерпретируемости используется корень из MSE, который имеет ту же размерность, что и исходные данные."
                    IsVisible="False"
                    Padding="10,20,10,10" />
            </StackLayout>

            <BoxView HeightRequest="1" Color="LightGray" Margin="0,10"/>

            <!-- Раздел: Вопросы -->
            <Label Text="Вопросы для самопроверки" 
                   FontSize="22" FontAttributes="Bold" 
                   TextColor="{StaticResource Primary}" Padding="15,0,0,0"/>

            <StackLayout Spacing="10" Padding="10">
                <Frame x:Name="question1_topic5" BackgroundColor="#F0F0F0" Padding="10">
                    <Frame.GestureRecognizers>
                        <TapGestureRecognizer Tapped="OnQuestionFrameTapped"/>
                    </Frame.GestureRecognizers>
                    <Label Text="Почему точность часто является недостаточной метрикой для оценки классификатора, и в каких случаях следует использовать F-меру?" FontSize="16"/>
                </Frame>
                <Label x:Name="answer1_topic5" 
                   Text="Точность учитывает лишь общую долю правильных ответов, что делает её крайне ненадёжной на несбалансированных данных. Например, если в выборке 95% объектов одного класса, модель, всегда предсказывающая этот класс, достигнет точности 95%, но при этом полностью проигнорирует миноритарный класс. F-мера, будучи гармоническим средним точности и полноты, позволяет получить сбалансированную оценку, особенно для положительного класса в условиях дисбаланса. Её следует использовать, когда важны как корректная идентификация объектов класса, так и минимизация ложных срабатываний, например, в задачах обнаружения заболеваний или фильтрации мошеннических операций."
                   IsVisible="False"
                   Padding="10,20,10,10" />
            </StackLayout>

            <StackLayout Spacing="10" Padding="10">
                <Frame x:Name="question2_topic5" BackgroundColor="#F0F0F0" Padding="10">
                    <Frame.GestureRecognizers>
                        <TapGestureRecognizer Tapped="OnQuestionFrameTapped"/>
                    </Frame.GestureRecognizers>
                    <Label Text="В чём принципиальное различие между метриками MSE и MAE, и как выбор между ними влияет на обучение модели?" FontSize="16"/>
                </Frame>
                <Label x:Name="answer2_topic5" 
                   Text="Принципиальное различие заключается в характере штрафа за ошибку. MSE (среднеквадратическая ошибка) возводит каждое отклонение в квадрат, что делает её высокочувствительной к большим ошибкам (выбросам). Минимизация MSE в процессе обучения заставляет модель в первую очередь избегать крупных промахов, иногда в ущерб общему качеству по малым отклонениям. MAE (средняя абсолютная ошибка) штрафует ошибки линейно, что делает её более робастной к аномальным значениям. Выбор метрики влияет на результат: минимизация MSE приведёт к модели, которая в среднем даёт меньшие крупные ошибки, но может иметь больше мелких неточностей, в то время как минимизация MAE даст модель, более равномерно распределяющую ошибки по всем объектам. MSE чаще используется, когда большие ошибки критически недопустимы, а MAE — когда все ошибки условно равнозначны и данные могут содержать шум."
                   IsVisible="False"
                   Padding="10,20,10,10" />
            </StackLayout>
        </VerticalStackLayout>
    </ScrollView>
</ContentPage>